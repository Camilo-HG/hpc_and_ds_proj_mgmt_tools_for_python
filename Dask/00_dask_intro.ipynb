{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ce1eb5-a8d5-448f-9aab-ec79d1d29034",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "    <a href=\"https://dask.org/\">\n",
    "    <img src=\"./images/dask_horizontal_white_no_pad.svg\" alt=\"Dask Logo\" style=\"background-color:black;\" width=\"900\" height=\"1200\"></a>\n",
    "    <br/>\n",
    "    <sup id=\"backref_IMG1\"><a href=\"#ref_IMG1\">1</a></sup>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25831c18-f041-453e-b4b3-d53b03b4dd00",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# What is [Dask](https://docs.dask.org/en/latest/)?\n",
    "\n",
    "> *Dask is a flexible library for parallel computing in Python*.\n",
    "\n",
    "According to the official documentation, Dask is composed of two parts:\n",
    "\n",
    "- **Dynamic task scheduling** optimized for computation that is optimized for interactive computational workloads.\n",
    "- **“Big Data” collections** like parallel arrays, dataframes, and lists that extend common interfaces like NumPy, Pandas, or Python iterators to larger-than-memory or distributed environments. These parallel collections run on top of dynamic task schedulers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a23e7-6da7-4ea5-8fd9-525ecefa9b73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# [Why Dask?](https://docs.dask.org/en/latest/why.html#links-and-more-information)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33c61d3-e638-4c34-bdb1-c94b44ad71c5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The popularity of Python as a coding language to power Data Science is evident, and this is thanks to its simplicity and low learning curve, and also thanks to powerful libraries such as [Numpy](https://numpy.org/), [Pandas](https://pandas.pydata.org/), and [scikit-learn](https://scikit-learn.org/stable/), which makes much easier manipulating and visualizing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aad088-3b9c-4b1f-a6e0-881723027710",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Nevertheless, all these libraries have a potentially huge problem for data scientists working with **Big Data** and **High Performance Computing (HPC)**: they are designed to run on a **single core**.\n",
    "\n",
    "As we should know, this fact makes us run into memory problems at the time when your data overfits RAM of our local system and the type of computation requires multicore processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1abf5e6-1c1c-4b09-9617-e5db9a89dbbe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# [Why Dask?](https://docs.dask.org/en/latest/why.html#links-and-more-information)\n",
    "\n",
    "[Dask](https://dask.org/) has been created to solve this problem, by distributing the data across multiple cores of the machine and providing ways to scale Pandas, Scikit-Learn, and Numpy workflows natively, with minimal rewriting, meaning you don’t have to learn an entire language and drastically change the way you wrote your code to implement Dask.\n",
    "\n",
    "The key concept here is that:\n",
    "\n",
    "> Dask aims to be a parallel computing library that works by distributing larger computations and breaking it down into smaller computations through a task scheduler and task workers, which has been designed to extend Numpy, Pandas and scikit-learn implementations without forcing Data Scientists to drastically change their code.\n",
    "\n",
    "What makes so great Dask is **_its ease of integration into the Python code_**.\n",
    "\n",
    "You can explore in more detail the reasons about [why people choose to adopt Dask](https://docs.dask.org/en/latest/why.html#links-and-more-information)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa915b-4b9d-4fc7-96e8-e3ff33f14aec",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# [Why Dask?](https://docs.dask.org/en/latest/why.html#links-and-more-information)\n",
    "\n",
    "## Key remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc3d15e-4797-42e8-8ee5-90227c9af275",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Dask scales out to Clusters\n",
    "\n",
    "Dask figures out how to break up large computations and route parts of them efficiently onto distributed hardware. Dask is routinely run on thousand-machine clusters to process hundreds of terabytes of data efficiently within secure environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22936065-07de-4c6f-bc6c-e68d1e336fd5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- Dask has utilities and documentation on how to deploy in-house, on the cloud, or on HPC super-computers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a9b942-b3e8-4875-93da-e1621aae51a9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- It supports encryption and authentication using TLS/SSL certificates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b55353-198e-492b-9fe3-98acaaa607ee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- It is resilient and can handle the failure of worker nodes gracefully and is elastic, and so can take advantage of new nodes added on-the-fly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e2bd63-b6f3-48c3-af8b-895ad65b4e71",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# [Why Dask?](https://docs.dask.org/en/latest/why.html#links-and-more-information)\n",
    "\n",
    "## Key remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5790bc-a227-4454-b06f-2b21b0452467",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Dask scales down to Single Computers\n",
    "\n",
    "Dask can enable efficient parallel computations on single machines by leveraging their multi-core CPUs and streaming data efficiently from disk.\n",
    "\n",
    "> It can run on a distributed cluster, but it doesn’t have to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c80a8-93af-4fbe-a675-e142aab1d96a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- Dask allows you to swap out the cluster for single-machine schedulers which are surprisingly lightweight, require no setup, and can run entirely within the same process as the user’s session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d635c4-3cbc-407c-8f3f-514911804dcf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- To avoid excess memory use, Dask is good at finding ways to evaluate computations in a low-memory footprint when possible by pulling in chunks of data from disk, doing the necessary processing, and throwing away intermediate values as quickly as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01791b98-60c0-4961-8580-1fa816f1e54e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Both capabilities above, require no configuration and no setup, meaning that:\n",
    "\n",
    "- Adding Dask to a single-machine computation adds very little cognitive overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04524245-c466-4ec7-a67f-1bfb0bfc2b0c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# [Why Dask?](https://docs.dask.org/en/latest/why.html#links-and-more-information)\n",
    "\n",
    "## Key remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ec0ae-b157-4593-9895-218b8a1755b6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Dask supports Complex Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627770bd-ad06-40af-b24d-14890898a470",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Some parallel computations are simple and just apply the same routine onto many inputs without any kind of coordination. These are simple to parallelize with any system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eea985-72c3-4749-be5b-1b115138a128",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Somewhat more complex computations can be expressed with the _map-shuffle-reduce_ pattern popularized by **Hadoop** and **Spark**. This is often sufficient to do most data cleaning tasks, database-style queries, and some lightweight machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc1b284-5c45-428f-8c3b-696fb431236a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "However\n",
    "\n",
    "> More complex parallel computations exist which do not fit into these paradigms, and so are difficult to perform with traditional big-data technologies. These include more advanced algorithms for statistics or machine learning, time series or local operations, or bespoke parallelism often found within the systems of large enterprises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b469e4f0-9a8b-4319-ae12-fcf3549a2790",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# [Why Dask?](https://docs.dask.org/en/latest/why.html#links-and-more-information)\n",
    "\n",
    "## Key remarks\n",
    "\n",
    "### Dask supports Complex Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb45a8e-b764-4bb5-a60a-dd2ddd570629",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Dask helps to resolve these situations by exposing low-level APIs to its internal task scheduler which is capable of executing very advanced computations.\n",
    "\n",
    "This gives engineers within the institution the ability to build their own parallel computing system using the same engine that powers Dask’s arrays, DataFrames, and machine learning algorithms, but now with the institution’s own custom logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb03d88b-d037-4c3b-9b4f-4c4a3e3c43cb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "> This allows engineers to keep complex business logic in-house while still relying on Dask to handle network communication, load balancing, resilience, diagnostics, etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220191c5-c315-4888-ba26-baa98f8e9d99",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# [Why Dask?](https://docs.dask.org/en/latest/why.html#links-and-more-information)\n",
    "\n",
    "## Key remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5457e766-4baf-4f8b-b21e-6ac4a09d331b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Dask Delivers Responsive Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a082e679-b30c-457c-897d-5be3e348d103",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Because everything happens remotely, interactive parallel computing can be frustrating for users. They don’t have a good sense of how computations are progressing, what might be going wrong, or what parts of their code should they focus on for performance. The added distance between a user and their computation can drastically affect how quickly they are able to identify and resolve bugs and performance problems, which can drastically increase their time to solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127475d9-0ca4-4c99-9bb1-b9d2cb4de3c2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Dask keeps users informed and content with a suite of helpful diagnostic and investigative tools including the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c67826-b0ae-43ec-a78f-8076f5e6484b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- A real-time and responsive dashboard that shows current progress, communication costs, memory use, and more, updated every 100ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53faedf2-1b35-434f-84c7-45f8fe26ca6c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- A statistical profiler installed on every worker that polls each thread every 10ms to determine which lines in your code are taking up the most time across your entire computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee9343-2044-484c-8484-59f9512e2229",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- An embedded IPython kernel in every worker and the scheduler, allowing users to directly investigate the state of their computation with a pop-up terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29509c1-8c58-4f54-8e10-1e8dc0a32ff6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- The ability to reraise errors locally, so that they can use the traditional debugging tools to which they are accustomed, even when the error happens remotely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7977ae-dabf-4a23-8f39-8690d264b359",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# How it works?\n",
    "\n",
    "<center>\n",
    "    <img src=\"./images/dask-overview.svg\" alt=\"Dask Overview\" width=\"500\" height=\"600\">\n",
    "    <br/>\n",
    "    <sup id=\"backref_IMG2\"><a href=\"#ref_IMG2\">2</a></sup>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c508cd-fbc1-4d60-a16f-04a343d948d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Dask use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ad349-0a16-4aad-868e-7b36ea64671c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Dask uses can be roughly divided in the following two categories:\n",
    "\n",
    "1. Large NumPy/Pandas/Lists with Dask Array, Dask DataFrame, Dask Bag, to analyze large datasets with familiar techniques. This is similar to [Spark](https://spark.apache.org) or big array libraries.\n",
    "\n",
    "2. **Custom task scheduling**. You submit a graph of functions that depend on each other for custom workloads. This is similar to [Airflow](https://airflow.apache.org) or [Celery](https://docs.celeryproject.org/en/stable/).\n",
    "\n",
    "Most people today approach Dask assuming it is a framework like Spark, designed for the first use case around large collections of uniformly shaped data. However, many of the more productive and novel use cases fall into the second category where Dask is used to parallelize custom workflows.\n",
    "\n",
    "You can also look for [real-world applications](https://stories.dask.org/en/latest/) in which people end up using both sides of Dask to achieve novel results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f59b4d5-fd47-4698-8e17-360ef7570de8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# References\n",
    "\n",
    "- [Dask Documentation](https://docs.dask.org/en/latest/)\n",
    "- [Dask: An Introduction and Tutorial](https://gongster.medium.com/dask-an-introduction-and-tutorial-b42f901bcff5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c9054-add1-4328-be96-3d76f7915cbd",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "# Images' references\n",
    "\n",
    "<a id=\"ref_IMG1\">1</a>: Taken from [Dask](https://dask.org/)\n",
    "    [↩](#backref_IMG1)\n",
    "    \n",
    "<a id=\"ref_IMG2\">2</a>: Taken from [Dask](https://dask.org/)\n",
    "    [↩](#backref_IMG2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
